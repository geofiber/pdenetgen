{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Exogeneous closure for the PKF applied to the Burgers dynamics </center></h1>\n",
    "<center>\n",
    "    Olivier Pannekoucke <br> 2020\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The aim is to train a closure to predict the uncertainty dynamics for the Burgers dynamics.\n",
    "\n",
    "The notebook present the situation where uknown physical processes are represented by an exogeneous NN to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "<center> <b>Table of contents</b> </center>\n",
    "\n",
    " 1. [Introduction](#introduction)\n",
    " 1. [The Burgers dynamics](#the-burgers-dynamics)\n",
    " 1. [PKF for the Burgers dynamics](#pkf-forthe-burgers-dynamics)\n",
    " 1. [Numerical application](#numerical-application)\n",
    "   - [Generation of a database](#generation-of-a-database)\n",
    "   - [Training of the closure](#training-of-the-closure)\n",
    "   - [Comparison with the theoretically designed closure](#comparison-with-the-theoretically-designed-closure)\n",
    " 1. [Conclusion](#conclusion)\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T13:49:35.003934Z",
     "start_time": "2018-11-29T13:49:34.831778Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to design a NN which merges known and unknown physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:05:22.911943Z",
     "start_time": "2018-10-03T09:05:22.699109Z"
    }
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "from sympy import (Function, symbols, init_printing, Derivative, \n",
    "                   latex, Add, Mul, Pow, \n",
    "                   Integer, Rational, Float, Symbol, symbol,\n",
    "                   srepr, Tuple\n",
    "                  )\n",
    "init_printing() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Burgers dynamics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdenetgen import NNModelBuilder, Eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_system(system):\n",
    "    print(50*'*')\n",
    "    for equation in system:\n",
    "        display(equation)\n",
    "        print(50*'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the function and symbols <a id='burgers-pkf-sympy-definition'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, x = symbols('t x')\n",
    "\n",
    "u = Function('u')(t,x)\n",
    "closure = sympy.Function('closure')(t,x)\n",
    "V = Function('{V_{u}}')(t,x)\n",
    "nu = Function('{\\\\nu_{u,xx}}')(t,x)\n",
    "Kappa = symbols('\\\\kappa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set constants for numerical experiments <a id='burgers-pkf-num-definition'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant setting following Pannekoucke et al. (2018)\n",
    "n = 241\n",
    "kappa = 0.0025\n",
    "dt = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the Burgers equation <a id='burgers-pkf-dyn-burgers'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers_dynamics = [\n",
    "        Eq(\n",
    "        Derivative(u,t),\n",
    "        Kappa*Derivative(u,x,2)-u*Derivative(u,x)\n",
    "      ),\n",
    "]\n",
    "display_system(burgers_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers_NN_builder = NNModelBuilder(burgers_dynamics, \"Burgers\")\n",
    "print(burgers_NN_builder.code)\n",
    "exec(burgers_NN_builder.code)\n",
    "burgers = Burgers(shape=(n,), kappa=kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of forecast from a given initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(data, label=None, labelx=True, title=None, save_file=None, normalisation=None, \n",
    "                 selected_times=None,style=None, name=None, alpha=1., bolds=[0., 1.]):\n",
    "    \n",
    "    normalisation = 1. if normalisation is None else normalisation\n",
    "                 \n",
    "    selected_times = [time for time in data] if selected_times is None else selected_times\n",
    "                 \n",
    "    style = 'k' if style is None else style\n",
    "                 \n",
    "    for time in selected_times:\n",
    "        lalpha = alpha if time in bolds else 0.2\n",
    "        lname = name if time==selected_times[-1] else None\n",
    "        plt.plot(domain.x[0],data[time]/normalisation, style, alpha = lalpha, label=lname)\n",
    "                 \n",
    "    if labelx:\n",
    "        plt.xlabel('$x/D$', fontsize=15)\n",
    "    if label:\n",
    "        plt.ylabel(label, fontsize=15)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if save_file:\n",
    "        plt.savefig(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = burgers\n",
    "# Set initial condition for 'u'\n",
    "U0=0.25*( 1+np.cos(2*np.pi/ domain.lengths[0]  *(domain.x[0]-0.25)) )\n",
    "Umax = U0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers.set_dt(dt)\n",
    "end_time_forecast = 1.\n",
    "times = burgers.window(end_time_forecast)\n",
    "saved_times = times[::50]\n",
    "print('saved_times :' ,saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = burgers.forecast(times, np.array([U0.reshape((1,)+U0.shape+(1,)) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in times:\n",
    "    plt.plot(domain.x[0], forecast[time][0,0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PKF for the Burgers dynamics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the PKF equations for the Burgers equation <a id='burgers-pkf-dyn-pkf'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Pannekoucke et al. (2018)\n",
    "\n",
    "pkf_dynamics = [\n",
    "    # Trend of the expectation of 'u'\n",
    "    Eq(\n",
    "        Derivative(u,t),\n",
    "        Kappa*Derivative(u,x,2)-u*Derivative(u,x)-Derivative(V,x)/Integer(2)\n",
    "      ),\n",
    "    # Trend of the variance\n",
    "    Eq(\n",
    "        Derivative(V,t),\n",
    "        -Kappa*V/nu + Kappa*Derivative(V,x,2)-Kappa*Derivative(V,x)**Integer(2)/(Integer(2)*V)\n",
    "        -u*Derivative(V,x)-Integer(2)*V*Derivative(u,x)\n",
    "      ),\n",
    "    # Trend of the diffusion\n",
    "    Eq(\n",
    "        Derivative(nu,t),\n",
    "        Integer(4)*Kappa*nu**Integer(2)*closure\n",
    "        -Integer(3)*Kappa*Derivative(nu,x,2)\n",
    "        -Kappa\n",
    "        +Integer(6)*Kappa*Derivative(nu,x)**Integer(2)/nu\n",
    "        -Integer(2)*Kappa*nu*Derivative(V,x,2)/V\n",
    "        +Kappa*Derivative(V,x)*Derivative(nu,x)/V\n",
    "        +Integer(2)*Kappa*nu*Derivative(V,x)**Integer(2)/V**Integer(2)\n",
    "        -u*Derivative(nu,x)\n",
    "        +Integer(2)*nu*Derivative(u,x)\n",
    "    )\n",
    "]\n",
    "\n",
    "display_system(pkf_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkf_NN_builder = NNModelBuilder(pkf_dynamics,'NN_Unclosed_PKF_Burgers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pkf_NN_builder.code)\n",
    "exec(pkf_NN_builder.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction of a closure as a NN from parameterized form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to compute the closure proposal\n",
    "$$a\\frac{\\frac{\\partial^{2}}{\\partial x^{2}} \\operatorname{{\\nu_{u,xx}}}{\\left(t,x \\right)}}{\\operatorname{{\\nu_{u,xx}}}^{2}{\\left(t,x \\right)}} +b \\frac{1}{ \\operatorname{{\\nu_{u,xx}}}^{2}{\\left(t,x \\right)}} +c\\frac{ \\left(\\frac{\\partial}{\\partial x} \\operatorname{{\\nu_{u,xx}}}{\\left(t,x \\right)}\\right)^{2}}{\\operatorname{{\\nu_{u,xx}}}^{3}{\\left(t,x \\right)}},$$\n",
    "as an exogeneous neural network, where $(a,b,c)$ are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClosedPKFBurgers(NN_Unclosed_PKF_Burgers):\n",
    "    def _make_exogenous_model(self):\n",
    "                \n",
    "        u = keras.layers.Input(shape=(self.input_shape_x,1))\n",
    "        V = keras.layers.Input(shape=(self.input_shape_x,1))\n",
    "        nu_u_xx = keras.layers.Input(shape=(self.input_shape_x,1))        \n",
    "        \n",
    "        #\n",
    "        # Computation of the spatial derivatives\n",
    "        #\n",
    "        \n",
    "        kernel_Dnu_u_xx_x_o2 = np.asarray([self.dx[self.coordinates.index('x')]**(-2),\n",
    "        -2/self.dx[self.coordinates.index('x')]**2,\n",
    "        self.dx[self.coordinates.index('x')]**(-2)]).reshape((3,)+(1,1))\n",
    "        Dnu_u_xx_x_o2 = DerivativeFactory((3,),kernel=kernel_Dnu_u_xx_x_o2,name='Dnu_u_xx_x_o2')(nu_u_xx)\n",
    "        \n",
    "        kernel_Dnu_u_xx_x_o1 = np.asarray([-1/(2*self.dx[self.coordinates.index('x')]),0.0,\n",
    "        1/(2*self.dx[self.coordinates.index('x')])]).reshape((3,)+(1,1))\n",
    "        Dnu_u_xx_x_o1 = DerivativeFactory((3,),kernel=kernel_Dnu_u_xx_x_o1,name='Dnu_u_xx_x_o1')(nu_u_xx)        \n",
    "        \n",
    "        #\n",
    "        # Design of the unknown closure to train\n",
    "        #\n",
    "        \n",
    "        # Terme 1\n",
    "        div_14 = keras.layers.Lambda(lambda x: 1/x,name='DivLayer_14')(nu_u_xx)\n",
    "        pow_12 = keras.layers.multiply([div_14,div_14,] ,name='PowLayer_12')\n",
    "        term1 = keras.layers.multiply([pow_12,Dnu_u_xx_x_o2],name='MulLayer_25')\n",
    "        \n",
    "        # Terme 2\n",
    "        div_13 = keras.layers.Lambda(lambda x: 1/x,name='DivLayer_13')(nu_u_xx)\n",
    "        term2 = keras.layers.multiply([div_13,div_13,] ,name='PowLayer_11')\n",
    "        \n",
    "        # Terme 3\n",
    "        pow_13 = keras.layers.multiply([Dnu_u_xx_x_o1,Dnu_u_xx_x_o1,] ,name='PowLayer_13')\n",
    "        div_15 = keras.layers.Lambda(lambda x: 1/x,name='DivLayer_15')(nu_u_xx)\n",
    "        pow_14 = keras.layers.multiply([div_15,div_15,div_15,] ,name='PowLayer_14')\n",
    "        term3 = keras.layers.multiply([pow_13,pow_14],name='MulLayer_26')\n",
    "        \n",
    "        # Product by (a,b,c), implemented as Conv1D\n",
    "        term1 = keras.layers.Conv1D(1,1,name='times_a',padding='same',use_bias=False,activation='linear')(term1)\n",
    "        term2 = keras.layers.Conv1D(1,1,name='times_b',padding='same',use_bias=False,activation='linear')(term2)\n",
    "        term3 = keras.layers.Conv1D(1,1,name='times_c',padding='same',use_bias=False,activation='linear')(term3)\n",
    "                \n",
    "        closure = keras.layers.add([term1, term2, term3],name='Closure')        \n",
    "                \n",
    "        self._exogenous_model = keras.models.Model(inputs=[u,V,nu_u_xx], outputs=[closure])\n",
    "        \n",
    "    def compute_exogenous(self, t, state):\n",
    "        \n",
    "        if self._exogenous_model is None:\n",
    "            self._make_exogenous_model()\n",
    "        \n",
    "        u,V,nu = state\n",
    "        closure = self._exogenous_model.predict([u,V,nu])\n",
    "        if not isinstance(closure, list):\n",
    "            closure = [closure]\n",
    "        return closure\n",
    "        \n",
    "    def _make_full_trend(self):\n",
    "        \n",
    "        if self._trend_model is None:\n",
    "            self._make_trend_model()\n",
    "        if self._exogenous_model is None:\n",
    "            self._make_exogenous_model()\n",
    "        \n",
    "        state = keras.layers.Input(shape=(3,self.input_shape_x,1))\n",
    "        \n",
    "        u = keras.layers.Lambda(lambda x : x[:,0,:,:])(state)\n",
    "        V = keras.layers.Lambda(lambda x : x[:,1,:,:])(state)\n",
    "        nu_u_xx = keras.layers.Lambda(lambda x : x[:,2,:,:])(state)\n",
    "        \n",
    "        closure = self._exogenous_model([u,V,nu_u_xx])\n",
    "        trend_u, trend_V, trend_nu = self._trend_model([u,V,nu_u_xx,closure])\n",
    "        \n",
    "        trend_u = keras.layers.Reshape((1,self.input_shape_x,1))(trend_u)\n",
    "        trend_V = keras.layers.Reshape((1,self.input_shape_x,1))(trend_V)\n",
    "        trend_nu = keras.layers.Reshape((1,self.input_shape_x,1))(trend_nu)\n",
    "        \n",
    "        trend = keras.layers.Concatenate(axis=1)([trend_u,trend_V,trend_nu])\n",
    "        self._full_trend = keras.models.Model(inputs=state,outputs=trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_burgers = ClosedPKFBurgers(shape=(241,),kappa=kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_burgers._make_full_trend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set initial PKF fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial condition for the variance parameter 'V_u'\n",
    "V0 = (0.01*Umax)**2 + 0*U0\n",
    "\n",
    "# Set the initial condition for the diffusion \n",
    "# L**2 = 2nu t => nu = 0.5*L**2\n",
    "lh = 0.02*domain.lengths[0]\n",
    "nu0 = 0.5*lh**2 + 0*U0\n",
    "\n",
    "state0 = np.asarray([U0, V0,nu0])\n",
    "normalization = {\n",
    "                'Velocity':U0.max(), \n",
    "                'Variance':V0.max(), \n",
    "                'Length-scale':lh\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_scale = lambda nu: np.sqrt(2*nu)\n",
    "plt.figure(figsize=(12,12))\n",
    "for k,field in enumerate(normalization):\n",
    "    plt.subplot(221+k)\n",
    "    if field=='Length-scale':\n",
    "        data = {0:length_scale(state0[k])}\n",
    "    else:\n",
    "        data = {0:state0[k]}\n",
    "    plot_results(data, label=field)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pkf_traj_ensemble(traj):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for k,field in enumerate(normalization):\n",
    "        if field=='Length-scale':\n",
    "            data = {time:length_scale(traj[time][k]) for time in traj}\n",
    "        else:\n",
    "            data = {time:traj[time][k] for time in traj}\n",
    "        plt.subplot(131+k)\n",
    "        plot_results(data,label=field,normalisation=normalization[field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pkf_traj_NN(traj):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for k,field in enumerate(normalization):\n",
    "        if field=='Length-scale':\n",
    "            data = {time:length_scale(traj[time][k][0,:,0]) for time in traj}\n",
    "        else:\n",
    "                data = {time:traj[time][k][0,:,0] for time in traj}\n",
    "        plt.subplot(131+k)\n",
    "        plot_results(data,label=field,normalisation=normalization[field])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state0 = np.asarray([U0.reshape((1,)+U0.shape+(1,)), \n",
    "                     V0.reshape((1,)+V0.shape+(1,)), \n",
    "                     nu0.reshape((1,)+nu0.shape+(1,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian random vector of Gaussian correlation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une matrice de covariance d'erreur de prévision initiale: $P_0$\n",
    "#   Cette matrice est construite comme une matrice homogène de corrélation Gaussienne et de longueur de portée l_h\n",
    "\n",
    "# 1) Définition de la fonction de corrélation homogène\n",
    "gauss = lambda x : np.exp(-0.5*x**2/lh**2) # lh has been previously specified \n",
    "correlation = gauss(domain.x[0]-domain.x[0][domain.shape[0]//2])\n",
    "spectrum = np.abs(np.fft.fft(correlation))\n",
    "\n",
    "# 2) Construction de B^(1/2)\n",
    "std_spectrum = np.sqrt(spectrum)\n",
    "def make_sample():\n",
    "    zeta = np.random.normal(size=domain.shape)\n",
    "    zeta = np.fft.fft(zeta)\n",
    "    ef = np.fft.ifft(std_spectrum * zeta)\n",
    "    ef = np.real(ef)\n",
    "    return ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(domain.x[0], correlation)\n",
    "plt.title('Homogenous correlation function');\n",
    "plt.subplot(122)\n",
    "for k in range(10):\n",
    "    plt.plot(domain.x[0], make_sample())\n",
    "plt.title(\"Example of sample errors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Diagnosis tool for ensemble estimation of expectation/variance/diffusion tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_init_ensemble(Ne):\n",
    "    return np.array([make_sample() for k in range(Ne)])\n",
    "\n",
    "def estimate_covariance(ensemble):\n",
    "    mean = ensemble.mean(0)\n",
    "    error = (ensemble - mean)/np.sqrt(len(ensemble))\n",
    "    return error.T @ error\n",
    "\n",
    "class EnsembleDiagnosis(object):\n",
    "    \n",
    "    def __init__(self, ensemble, base_space):\n",
    "        self.base_space = base_space\n",
    "        \n",
    "        if isinstance(ensemble, list):\n",
    "            ensemble = np.array(ensemble)\n",
    "        \n",
    "        if len(ensemble.shape)==3:\n",
    "            ensemble = np.array([elm[0] for elm in ensemble])\n",
    "        \n",
    "        # 1) Computation of the mean\n",
    "        self.mean = ensemble.mean(axis=0)\n",
    "        \n",
    "        # 2) Computation of the variance\n",
    "        self.std = ensemble.std(axis=0)\n",
    "        self.variance = self.std*self.std\n",
    "        \n",
    "        # 3) Computation of the metric terms \n",
    "        #  we use the formula g_ij = E[(D_i eps)(D_j eps)]\n",
    "        \n",
    "        #  a) Computation of the normalized error\n",
    "        epsilon = (ensemble-self.mean)/self.std\n",
    "        \n",
    "        #  b) Computation of derivatives\n",
    "        n = self.base_space.shape[0]\n",
    "        K = np.arange(n)\n",
    "        kp = (K+1)%n\n",
    "        km = (K-1)%n\n",
    "        dx = self.base_space.dx[0]\n",
    "        Depsilon = np.array([(eps[kp]-eps[km])/(2*dx) for eps in epsilon])\n",
    "        self.metric = (Depsilon*Depsilon).mean(axis=0)     # see Pannekoucke et al. (2018) for details   \n",
    "        \n",
    "        # Computation of the diffusion tensor\n",
    "        self.diffusion = 0.5*1/self.metric\n",
    "        self.length_scale = np.sqrt(2*self.diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ensemble validation for the covariance setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne = 1600\n",
    "\n",
    "ensemble = make_init_ensemble(Ne)\n",
    "\n",
    "mean = ensemble.mean(axis=0)\n",
    "std = ensemble.std(axis=0)\n",
    "\n",
    "print(f\"Validation of the mean (=0): {mean.mean()} +/- {mean.std()}\" )\n",
    "print(f\"Validation of the standard-deviation (=1): {std.mean()} +/- {std.std()}\" )\n",
    "\n",
    "ens_diagnosis = EnsembleDiagnosis(ensemble, domain)\n",
    "nu_h = 0.5*lh**2\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(ens_diagnosis.mean)\n",
    "plt.title('Moyenne')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(ens_diagnosis.variance)\n",
    "plt.title('Variance')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(ens_diagnosis.diffusion/nu_h)\n",
    "plt.title('diffusion (normalisée par $nu_h$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computation of a large ensemble (1600 members) to build a reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation for the initial perturbation\n",
    "sigma_f = 0.01*U0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for ensemble estimation\n",
    "large_Ne = 1600\n",
    "\n",
    "# 1. Set the initial background state\n",
    "random_U0 = U0 + sigma_f*make_init_ensemble(1)[0]\n",
    "\n",
    "# 2. Build an ensemble of initial perturbed state\n",
    "ensemble = make_init_ensemble(large_Ne)\n",
    "ensemble_ea = np.array([random_U0+sigma_f*ea for ea in ensemble])\n",
    "ensemble_ea = ensemble_ea.reshape((1,)+ensemble_ea.shape+(1,))\n",
    "print(f\"shape of ensemble_ea: {ensemble_ea.shape}\")\n",
    "\n",
    "# 3. Build the ensemble of forecast using the NN architecture\n",
    "ensemble_forecast = burgers.forecast(times,ensemble_ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compute diagnosis from ensemble\n",
    "ensemble_traj = {}\n",
    "for time in times[::50]:\n",
    "    diagnosis = EnsembleDiagnosis(ensemble_forecast[time][0,:,:,0], domain)\n",
    "    ensemble_traj[time] = [diagnosis.mean, diagnosis.variance, diagnosis.diffusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pkf_traj_ensemble(ensemble_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generation of the training data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(k, Ne=400):\n",
    "    # 1. Set the initial background state\n",
    "    random_U0 = U0 + sigma_f*make_init_ensemble(1)[0]\n",
    "\n",
    "    # 2. Build an ensemble of initial perturbed state\n",
    "    ensemble = make_init_ensemble(Ne)\n",
    "    ensemble_ea = np.array([random_U0+sigma_f*ea for ea in ensemble])\n",
    "    ensemble_ea = ensemble_ea.reshape((1,)+ensemble_ea.shape+(1,))    \n",
    "        \n",
    "    # 3. Compute the ensemble of forecasts\n",
    "    ensemble_forecast = burgers.forecast(times,ensemble_ea)\n",
    "\n",
    "    # 4. Compute the diagnosis    \n",
    "    diagnosis_list = []\n",
    "    for time in times:\n",
    "        diagnosis = EnsembleDiagnosis(ensemble_forecast[time][0,:,:,0], domain)\n",
    "        diagnosis_list.append( np.array([diagnosis.mean, diagnosis.variance, diagnosis.diffusion]))\n",
    "        \n",
    "    return diagnosis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 400  # for Ne=400, this takes 1h09'01'' so take care with this..\n",
    "save_file = \"pkf-dataset.npy\"\n",
    "\n",
    "generate_data_set = False\n",
    "parallel_diagnosis = False\n",
    "    \n",
    "try:\n",
    "    # load data\n",
    "    data = np.load(save_file)\n",
    "    data = data.reshape(data.shape+(1,))\n",
    "except:\n",
    "    # 1. Generate data   \n",
    "    #data = [generate_data(k) for k in range(data_size)]\n",
    "    data = []\n",
    "    for k in range(data_size):\n",
    "        if k%5==0:\n",
    "            print(k)\n",
    "        data.append(generate_data(k))\n",
    "    \n",
    "\n",
    "    # 2. Save data\n",
    "    data = np.array(data)\n",
    "    np.save(save_file,data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the closure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a RK4 time scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schéma temporelle de type RK4\n",
    "def make_time_scheme(dt, trend):\n",
    "    \"\"\" Implémentation d'un schéma de RK4 sous forme de réseau de neurones \"\"\"\n",
    "    import tensorflow.keras as keras\n",
    "    \n",
    "    state = keras.layers.Input(shape = trend.input_shape[1:])\n",
    "    \n",
    "    # k1 \n",
    "    k1 = trend(state)\n",
    "    # k2 \n",
    "    _tmp_1 = keras.layers.Lambda(lambda x : 0.5*dt*x)(k1)\n",
    "    input_k2 = keras.layers.add([state,_tmp_1])\n",
    "    k2 = trend(input_k2)\n",
    "    # k3 \n",
    "    _tmp_2 = keras.layers.Lambda(lambda x : 0.5*dt*x)(k2)\n",
    "    input_k3 = keras.layers.add([state,_tmp_2])\n",
    "    k3 = trend(input_k3)\n",
    "    # k4 \n",
    "    _tmp_3 = keras.layers.Lambda(lambda x : dt*x)(k3)\n",
    "    input_k4 = keras.layers.add([state,_tmp_3])\n",
    "    k4 = trend(input_k4)\n",
    "    \n",
    "    # output\n",
    "    # k2+k3\n",
    "    add_k2_k3 = keras.layers.add([k2,k3])\n",
    "    add_k2_k3_mul2 = keras.layers.Lambda(lambda x:2.*x)(add_k2_k3)\n",
    "    # Add k1,k4\n",
    "    _sum = keras.layers.add([k1,add_k2_k3_mul2,k4])\n",
    "    # *dt\n",
    "    _sc_mul = keras.layers.Lambda(lambda x:dt/6.*x)(_sum)\n",
    "    output = keras.layers.add([state, _sc_mul])\n",
    "    \n",
    "    time_scheme = keras.models.Model(inputs =[state], outputs=[output])\n",
    "    return time_scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers = ClosedPKFBurgers(shape=(241,),kappa=kappa)\n",
    "\n",
    "closed_pkf_burgers._make_full_trend()\n",
    "\n",
    "trained = closed_pkf_burgers._full_trend.get_weights()\n",
    "trained = np.array((trained[0], trained[1], trained[2])).flatten()\n",
    "trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._make_full_trend()\n",
    "closed_pkf_burgers._full_trend.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._exogenous_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scheme = make_time_scheme(dt, closed_pkf_burgers._full_trend)\n",
    "#time_scheme.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract data for the training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_from = 400 # 200\n",
    "X = np.array([elm[select_from:-1] for elm in data])\n",
    "Y = np.array([elm[select_from+1:] for elm in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((np.prod(X.shape[:2]),3,241,1))\n",
    "Y = Y.reshape((np.prod(Y.shape[:2]),3,241,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training of the NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = closed_pkf_burgers._full_trend.get_weights()\n",
    "trained = np.array((trained[0], trained[1], trained[2])).flatten()\n",
    "trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expérience d'apprentissage:\n",
    "# 2. Adam\n",
    "lr = 0.1 \n",
    "epochs = 30 \n",
    "\n",
    "for iteration in range(3):\n",
    "    # 1. Set the learning\n",
    "    time_scheme.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "        loss='mean_squared_error') \n",
    "    \n",
    "    # 2. Train\n",
    "    history = time_scheme.fit(X,Y,epochs=epochs, batch_size=32,verbose=0)\n",
    "    print(f\"iteration {iteration} is complet\")\n",
    "    \n",
    "    # 3. Plot history    \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    \n",
    "    # 4. Update the learning rate for next iteration\n",
    "    lr = lr/10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the theoretically designed closure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the weights with the previous theoretical closure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of the theoretical closure are : 1, 3/4, -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = closed_pkf_burgers._full_trend.get_weights()\n",
    "trained = np.array((trained[0], trained[1], trained[2])).flatten()\n",
    "trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical = np.array([1,3/4,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error = (trained - theoretical)/theoretical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de prévision réalisée avec le modèle calibré**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "closed_pkf_burgers.set_dt(dt)\n",
    "times = closed_pkf_burgers.window(1)\n",
    "saved_times = times[::50]\n",
    "print('saved_times :' ,saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_unclosed_traj = closed_pkf_burgers.forecast(times, state0, saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKF using trained closure\n",
    "plot_pkf_traj_NN(trained_unclosed_traj)\n",
    "plt.savefig('./figures/burgers-exogeneous-b.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble of forecast statistics\n",
    "plot_pkf_traj_ensemble(ensemble_traj)\n",
    "plt.savefig('./figures/burgers-exogeneous-a.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a id='conclusion'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have considered the uncertainty prediction for the Burgers dynamics where an unclosed term is present.\n",
    "\n",
    "A closure has been proposed and implemented as an exogeneous neural network with three unknowns.\n",
    "\n",
    "A synthetic dataset has been  used to train the NN. The resulting closure has shown to be relevant to predict the uncertainty."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "nav_menu": {
    "height": "244px",
    "width": "212px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
