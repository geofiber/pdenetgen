{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Training of a closure designed with `TrainableScalar` for the PKF applied to the Burgers dynamics </center></h1>\n",
    "<center>\n",
    "    Olivier Pannekoucke <br> 2020\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The aim is to train a closure to predict the uncertainty dynamics for the Burgers dynamics.\n",
    "\n",
    "The notebook present the situation where uknown physical processes are represented by a symbolic expression where `TrainableScalar` are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "<center> <b>Table of contents</b> </center>\n",
    "\n",
    " 1. [Introduction](#introduction)\n",
    " 1. [The Burgers dynamics](#the-burgers-dynamics)\n",
    " 1. [PKF for the Burgers dynamics](#pkf-forthe-burgers-dynamics)\n",
    " 1. [Numerical application](#numerical-application)\n",
    "   - [Generation of a database](#generation-of-a-database)\n",
    "   - [Training of the closure](#training-of-the-closure)\n",
    "   - [Comparison with the theoretically designed closure](#comparison-with-the-theoretically-designed-closure)\n",
    " 1. [Conclusion](#conclusion)\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T13:49:35.003934Z",
     "start_time": "2018-11-29T13:49:34.831778Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id='introduction'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to design a NN which merges known and unknown physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:05:22.911943Z",
     "start_time": "2018-10-03T09:05:22.699109Z"
    }
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "from sympy import (Function, symbols, init_printing, Derivative, \n",
    "                   latex, Add, Mul, Pow, \n",
    "                   Integer, Rational, Float, Symbol, symbol,\n",
    "                   srepr, Tuple\n",
    "                  )\n",
    "init_printing() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Burgers dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdenetgen import NNModelBuilder, Eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_system(system):\n",
    "    print(50*'*')\n",
    "    for equation in system:\n",
    "        display(equation)\n",
    "        print(50*'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the function and symbols <a id='burgers-pkf-sympy-definition'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, x = symbols('t x')\n",
    "\n",
    "u = Function('u')(t,x)\n",
    "closure = sympy.Function('closure')(t,x)\n",
    "V = Function('{V_{u}}')(t,x)\n",
    "nu = Function('{\\\\nu_{u,xx}}')(t,x)\n",
    "Kappa = symbols('\\\\kappa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set constants for numerical experiments <a id='burgers-pkf-num-definition'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant setting following Pannekoucke et al. (2018)\n",
    "n = 241\n",
    "kappa = 0.0025\n",
    "dt = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the Burgers equation <a id='burgers-pkf-dyn-burgers'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers_dynamics = [\n",
    "        Eq(\n",
    "        Derivative(u,t),\n",
    "        Kappa*Derivative(u,x,2)-u*Derivative(u,x)\n",
    "      ),\n",
    "]\n",
    "display_system(burgers_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers_NN_builder = NNModelBuilder(burgers_dynamics, \"Burgers\")\n",
    "print(burgers_NN_builder.code)\n",
    "exec(burgers_NN_builder.code)\n",
    "burgers = Burgers(shape=(n,), kappa=kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of forecast from a given initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(data, label=None, labelx=True, title=None, save_file=None, normalisation=None, \n",
    "                 selected_times=None,style=None, name=None, alpha=1., bolds=[0., 1.]):\n",
    "    \n",
    "    normalisation = 1. if normalisation is None else normalisation\n",
    "                 \n",
    "    selected_times = [time for time in data] if selected_times is None else selected_times\n",
    "                 \n",
    "    style = 'k' if style is None else style\n",
    "                 \n",
    "    for time in selected_times:\n",
    "        lalpha = alpha if time in bolds else 0.2\n",
    "        lname = name if time==selected_times[-1] else None\n",
    "        plt.plot(domain.x[0],data[time]/normalisation, style, alpha = lalpha, label=lname)\n",
    "                 \n",
    "    if labelx:\n",
    "        plt.xlabel('$x/D$', fontsize=15)\n",
    "    if label:\n",
    "        plt.ylabel(label, fontsize=15)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if save_file:\n",
    "        plt.savefig(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = burgers\n",
    "# Set initial condition for 'u'\n",
    "U0=0.25*( 1+np.cos(2*np.pi/ domain.lengths[0]  *(domain.x[0]-0.25)) )\n",
    "Umax = U0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers.set_dt(dt)\n",
    "end_time_forecast = 1.\n",
    "times = burgers.window(end_time_forecast)\n",
    "saved_times = times[::50]\n",
    "print('saved_times :' ,saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = burgers.forecast(times, np.array([U0.reshape((1,)+U0.shape+(1,)) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in times:\n",
    "    plt.plot(domain.x[0], forecast[time][0,0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PKF for the Burgers dynamics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the PKF equations for the Burgers equation <a id='burgers-pkf-dyn-pkf'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Pannekoucke et al. (2018)\n",
    "\n",
    "pkf_dynamics = [\n",
    "    # Trend of the expectation of 'u'\n",
    "    Eq(\n",
    "        Derivative(u,t),\n",
    "        Kappa*Derivative(u,x,2)-u*Derivative(u,x)-Derivative(V,x)/Integer(2)\n",
    "      ),\n",
    "    # Trend of the variance\n",
    "    Eq(\n",
    "        Derivative(V,t),\n",
    "        -Kappa*V/nu + Kappa*Derivative(V,x,2)-Kappa*Derivative(V,x)**Integer(2)/(Integer(2)*V)\n",
    "        -u*Derivative(V,x)-Integer(2)*V*Derivative(u,x)\n",
    "      ),\n",
    "    # Trend of the diffusion\n",
    "    Eq(\n",
    "        Derivative(nu,t),\n",
    "        Integer(4)*Kappa*nu**Integer(2)*closure\n",
    "        -Integer(3)*Kappa*Derivative(nu,x,2)\n",
    "        -Kappa\n",
    "        +Integer(6)*Kappa*Derivative(nu,x)**Integer(2)/nu\n",
    "        -Integer(2)*Kappa*nu*Derivative(V,x,2)/V\n",
    "        +Kappa*Derivative(V,x)*Derivative(nu,x)/V\n",
    "        +Integer(2)*Kappa*nu*Derivative(V,x)**Integer(2)/V**Integer(2)\n",
    "        -u*Derivative(nu,x)\n",
    "        +Integer(2)*nu*Derivative(u,x)\n",
    "    )\n",
    "]\n",
    "\n",
    "display_system(pkf_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction of the closure ine the PKF dynamics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdenetgen import TrainableScalar\n",
    "\n",
    "# Set the closure by using TrainableScalar\n",
    "a, b, c = [TrainableScalar(l) for l in 'abc']\n",
    "closure_proposal = a*Derivative(nu,x,2)/nu**Integer(2)+b*1/nu**Integer(2)+\\\n",
    "                c*Derivative(nu,x)**2/nu**Integer(3)\n",
    "display(closure_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the closure(t,x) by the proposed closure\n",
    "pkf_dynamics[2] = pkf_dynamics[2].subs(Function('closure')(t,x), closure_proposal)\n",
    "\n",
    "# Generate the NN code leading to the ClosedPKFBurgers class.\n",
    "exec(NNModelBuilder(pkf_dynamics,'ClosedPKFBurgers').code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample of code generated to define the ClosedPKFBurgers class**\n",
    "```python\n",
    "[..]\n",
    "pow_21 = keras.layers.multiply([div_17,div_17,] ,name='PowLayer_21')\n",
    "mul_28 = keras.layers.multiply([pow_21,Dnu_u_xx_x_o2],name='MulLayer_28')\n",
    "train_scalar_9 = TrainableScalarLayerFactory(input_shape=mul_28.shape, name='TrainableScalar_a', \n",
    "                init_value=0,use_bias=False,mean=0.0,stddev=1.0,seed=None,wl2=None)(mul_28)                \n",
    "                #TrainableScalar name: 'a' \n",
    "add_8 = keras.layers.add([train_scalar_7,train_scalar_8,train_scalar_9],name='AddLayer_8')\n",
    "mul_26 = keras.layers.multiply([pow_17,add_8],name='MulLayer_26')\n",
    "[..]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NNModelBuilder(pkf_dynamics,'ClosedPKFBurgers').code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the closed PKF dynamics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_system(pkf_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set initial PKF fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial condition for the variance parameter 'V_u'\n",
    "V0 = (0.01*Umax)**2 + 0*U0\n",
    "\n",
    "# Set the initial condition for the diffusion \n",
    "# L**2 = 2nu t => nu = 0.5*L**2\n",
    "lh = 0.02*domain.lengths[0]\n",
    "nu0 = 0.5*lh**2 + 0*U0\n",
    "\n",
    "state0 = np.asarray([U0, V0,nu0])\n",
    "normalization = {\n",
    "                'Velocity':U0.max(), \n",
    "                'Variance':V0.max(), \n",
    "                'Length-scale':lh\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_scale = lambda nu: np.sqrt(2*nu)\n",
    "plt.figure(figsize=(12,12))\n",
    "for k,field in enumerate(normalization):\n",
    "    plt.subplot(221+k)\n",
    "    if field=='Length-scale':\n",
    "        data = {0:length_scale(state0[k])}\n",
    "    else:\n",
    "        data = {0:state0[k]}\n",
    "    plot_results(data, label=field)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pkf_traj_ensemble(traj):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for k,field in enumerate(normalization):\n",
    "        if field=='Length-scale':\n",
    "            data = {time:length_scale(traj[time][k]) for time in traj}\n",
    "        else:\n",
    "            data = {time:traj[time][k] for time in traj}\n",
    "        plt.subplot(131+k)\n",
    "        plot_results(data,label=field,normalisation=normalization[field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state0 = np.asarray([U0.reshape((1,)+U0.shape+(1,)), \n",
    "                     V0.reshape((1,)+V0.shape+(1,)), \n",
    "                     nu0.reshape((1,)+nu0.shape+(1,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pkf_traj_NN(traj):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for k,field in enumerate(normalization):\n",
    "        if field=='Length-scale':\n",
    "            data = {time:length_scale(traj[time][k][0,:,0]) for time in traj}\n",
    "        else:\n",
    "                data = {time:traj[time][k][0,:,0] for time in traj}\n",
    "        plt.subplot(131+k)\n",
    "        plot_results(data,label=field,normalisation=normalization[field])\n",
    "    \n",
    "#plt.savefig(\"./figures/NN-PKF-closure_loc-gaussian.jpg\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of a database <a id='set-database'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Gaussian random vector of Gaussian correlation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une matrice de covariance d'erreur de prévision initiale: $P_0$\n",
    "#   Cette matrice est construite comme une matrice homogène de corrélation Gaussienne et de longueur de portée l_h\n",
    "\n",
    "# 1) Définition de la fonction de corrélation homogène\n",
    "gauss = lambda x : np.exp(-0.5*x**2/lh**2) # lh has been previously specified \n",
    "correlation = gauss(domain.x[0]-domain.x[0][domain.shape[0]//2])\n",
    "spectrum = np.abs(np.fft.fft(correlation))\n",
    "\n",
    "# 2) Construction de B^(1/2)\n",
    "std_spectrum = np.sqrt(spectrum)\n",
    "def make_sample():\n",
    "    zeta = np.random.normal(size=domain.shape)\n",
    "    zeta = np.fft.fft(zeta)\n",
    "    ef = np.fft.ifft(std_spectrum * zeta)\n",
    "    ef = np.real(ef)\n",
    "    return ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(domain.x[0], correlation)\n",
    "plt.title('Homogenous correlation function');\n",
    "plt.subplot(122)\n",
    "for k in range(10):\n",
    "    plt.plot(domain.x[0], make_sample())\n",
    "plt.title(\"Example of sample errors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Diagnosis tool for ensemble estimation of expectation/variance/diffusion tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_init_ensemble(Ne):\n",
    "    return np.array([make_sample() for k in range(Ne)])\n",
    "\n",
    "def estimate_covariance(ensemble):\n",
    "    mean = ensemble.mean(0)\n",
    "    error = (ensemble - mean)/np.sqrt(len(ensemble))\n",
    "    return error.T @ error\n",
    "\n",
    "class EnsembleDiagnosis(object):\n",
    "    \n",
    "    def __init__(self, ensemble, base_space):\n",
    "        self.base_space = base_space\n",
    "        \n",
    "        if isinstance(ensemble, list):\n",
    "            ensemble = np.array(ensemble)\n",
    "        \n",
    "        if len(ensemble.shape)==3:\n",
    "            ensemble = np.array([elm[0] for elm in ensemble])\n",
    "        \n",
    "        # 1) Computation of the mean\n",
    "        self.mean = ensemble.mean(axis=0)\n",
    "        \n",
    "        # 2) Computation of the variance\n",
    "        self.std = ensemble.std(axis=0)\n",
    "        self.variance = self.std*self.std\n",
    "        \n",
    "        # 3) Computation of the metric terms \n",
    "        #  we use the formula g_ij = E[(D_i eps)(D_j eps)]\n",
    "        \n",
    "        #  a) Computation of the normalized error\n",
    "        epsilon = (ensemble-self.mean)/self.std\n",
    "        \n",
    "        #  b) Computation of derivatives\n",
    "        n = self.base_space.shape[0]\n",
    "        K = np.arange(n)\n",
    "        kp = (K+1)%n\n",
    "        km = (K-1)%n\n",
    "        dx = self.base_space.dx[0]\n",
    "        Depsilon = np.array([(eps[kp]-eps[km])/(2*dx) for eps in epsilon])\n",
    "        self.metric = (Depsilon*Depsilon).mean(axis=0)     # see Pannekoucke et al. (2018) for details   \n",
    "        \n",
    "        # Computation of the diffusion tensor\n",
    "        self.diffusion = 0.5*1/self.metric\n",
    "        self.length_scale = np.sqrt(2*self.diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ensemble validation for the covariance setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne = 1600\n",
    "\n",
    "ensemble = make_init_ensemble(Ne)\n",
    "\n",
    "mean = ensemble.mean(axis=0)\n",
    "std = ensemble.std(axis=0)\n",
    "\n",
    "print(f\"Validation of the mean (=0): {mean.mean()} +/- {mean.std()}\" )\n",
    "print(f\"Validation of the standard-deviation (=1): {std.mean()} +/- {std.std()}\" )\n",
    "\n",
    "ens_diagnosis = EnsembleDiagnosis(ensemble, domain)\n",
    "nu_h = 0.5*lh**2\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(ens_diagnosis.mean)\n",
    "plt.title('Moyenne')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(ens_diagnosis.variance)\n",
    "plt.title('Variance')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(ens_diagnosis.diffusion/nu_h)\n",
    "plt.title('diffusion (normalisée par $nu_h$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computation of a large ensemble (1600 members) to build a reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation for the initial perturbation\n",
    "sigma_f = 0.01*U0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for ensemble estimation\n",
    "if debug:\n",
    "    large_Ne = 50\n",
    "else:\n",
    "    large_Ne = 1600\n",
    "\n",
    "# 1. Set the initial background state\n",
    "random_U0 = U0 + sigma_f*make_init_ensemble(1)[0]\n",
    "\n",
    "# 2. Build an ensemble of initial perturbed state\n",
    "ensemble = make_init_ensemble(large_Ne)\n",
    "ensemble_ea = np.array([random_U0+sigma_f*ea for ea in ensemble])\n",
    "ensemble_ea = ensemble_ea.reshape((1,)+ensemble_ea.shape+(1,))\n",
    "print(f\"shape of ensemble_ea: {ensemble_ea.shape}\")\n",
    "\n",
    "# 3. Build the ensemble of forecast using the NN architecture\n",
    "ensemble_forecast = burgers.forecast(times,ensemble_ea)\n",
    "\n",
    "# 4. Compute diagnosis from ensemble\n",
    "ensemble_traj = {}\n",
    "for time in times[::50]:\n",
    "    diagnosis = EnsembleDiagnosis(ensemble_forecast[time][0,:,:,0], domain)\n",
    "    ensemble_traj[time] = [diagnosis.mean, diagnosis.variance, diagnosis.diffusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pkf_traj_ensemble(ensemble_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generation of the training data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(k, Ne=400):\n",
    "    # 1. Set the initial background state\n",
    "    random_U0 = U0 + sigma_f*make_init_ensemble(1)[0]\n",
    "\n",
    "    # 2. Build an ensemble of initial perturbed state\n",
    "    ensemble = make_init_ensemble(Ne)\n",
    "    ensemble_ea = np.array([random_U0+sigma_f*ea for ea in ensemble])\n",
    "    ensemble_ea = ensemble_ea.reshape((1,)+ensemble_ea.shape+(1,))    \n",
    "        \n",
    "    # 3. Compute the ensemble of forecasts\n",
    "    ensemble_forecast = burgers.forecast(times,ensemble_ea)\n",
    "\n",
    "    # 4. Compute the diagnosis    \n",
    "    diagnosis_list = []\n",
    "    for time in times:\n",
    "        diagnosis = EnsembleDiagnosis(ensemble_forecast[time][0,:,:,0], domain)\n",
    "        diagnosis_list.append( np.array([diagnosis.mean, diagnosis.variance, diagnosis.diffusion]))\n",
    "        \n",
    "    return diagnosis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 400  # for Ne=400, this takes 1h09'01'' so take care with this..\n",
    "save_file = \"pkf-dataset.npy\"\n",
    "\n",
    "generate_data_set = False\n",
    "parallel_diagnosis = False\n",
    "    \n",
    "try:\n",
    "    # load data\n",
    "    data = np.load(save_file)\n",
    "    data = data.reshape(data.shape+(1,))\n",
    "except:\n",
    "    # 1. Generate data   \n",
    "    #data = [generate_data(k) for k in range(data_size)]\n",
    "    data = []\n",
    "    for k in range(data_size):\n",
    "        if k%5==0:\n",
    "            print(k)\n",
    "        data.append(generate_data(k))\n",
    "    \n",
    "\n",
    "    # 2. Save data\n",
    "    data = np.array(data)\n",
    "    np.save(save_file,data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the closure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a RK4 time scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_scheme(dt, trend):\n",
    "    \"\"\" Implementation of an RK4 with Keras \"\"\"\n",
    "    #import tensorflow.keras as keras\n",
    "    import tensorflow.keras as keras\n",
    "    \n",
    "    state = keras.layers.Input(shape = trend.input_shape[1:])\n",
    "    \n",
    "    # k1 \n",
    "    k1 = trend(state)\n",
    "    # k2 \n",
    "    _tmp_1 = keras.layers.Lambda(lambda x : 0.5*dt*x)(k1)\n",
    "    input_k2 = keras.layers.add([state,_tmp_1])\n",
    "    k2 = trend(input_k2)\n",
    "    # k3 \n",
    "    _tmp_2 = keras.layers.Lambda(lambda x : 0.5*dt*x)(k2)\n",
    "    input_k3 = keras.layers.add([state,_tmp_2])\n",
    "    k3 = trend(input_k3)\n",
    "    # k4 \n",
    "    _tmp_3 = keras.layers.Lambda(lambda x : dt*x)(k3)\n",
    "    input_k4 = keras.layers.add([state,_tmp_3])\n",
    "    k4 = trend(input_k4)\n",
    "    \n",
    "    # output\n",
    "    # k2+k3\n",
    "    add_k2_k3 = keras.layers.add([k2,k3])\n",
    "    add_k2_k3_mul2 = keras.layers.Lambda(lambda x:2.*x)(add_k2_k3)\n",
    "    # Add k1,k4\n",
    "    _sum = keras.layers.add([k1,add_k2_k3_mul2,k4])\n",
    "    # *dt\n",
    "    _sc_mul = keras.layers.Lambda(lambda x:dt/6.*x)(_sum)\n",
    "    output = keras.layers.add([state, _sc_mul])\n",
    "    \n",
    "    time_scheme = keras.models.Model(inputs =[state], \n",
    "                                     outputs=[output])\n",
    "    return time_scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers = ClosedPKFBurgers(shape=(241,),kappa=kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._make_dynamical_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scheme = make_time_scheme(dt, closed_pkf_burgers._dynamical_trend)\n",
    "#time_scheme.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._dynamical_trend.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constitution de la base de données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_from = 400 # 200\n",
    "X = np.array([elm[select_from:-1] for elm in data])\n",
    "Y = np.array([elm[select_from+1:] for elm in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((np.prod(X.shape[:2]),3,241,1))\n",
    "Y = Y.reshape((np.prod(Y.shape[:2]),3,241,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training of the NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._trend_model.get_layer('TrainableScalar_a').get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value of the unknowns (a,b,c) before the training\n",
    "untrained = []\n",
    "for l in \"abc\":\n",
    "    untrained.append(float(closed_pkf_burgers._trend_model.get_layer('TrainableScalar_'+l).get_weights()[0]))\n",
    "    print(f\"{l}: {untrained[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._dynamical_trend.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expérience d'apprentissage:\n",
    "# 2. Adam\n",
    "lr = 0.1 \n",
    "epochs = 30\n",
    "\n",
    "for iteration in range(3):\n",
    "    # 1. Set the learning\n",
    "    time_scheme.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "        loss='mean_squared_error') \n",
    "    \n",
    "    # 2. Train\n",
    "    history = time_scheme.fit(X,Y,epochs=epochs, batch_size=32,verbose=0)\n",
    "    print(f\"iteration {iteration} is complet\")\n",
    "    \n",
    "    # 3. Plot history    \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    \n",
    "    # 4. Update the learning rate for next iteration\n",
    "    lr = lr/10\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the theoretically designed closure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the weights with the previous theoretical closure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closed_pkf_burgers._trend_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = []\n",
    "for l in \"abc\":\n",
    "    trained.append(float(closed_pkf_burgers._trend_model.get_layer('TrainableScalar_'+l).get_weights()[0]))\n",
    "    print(f\"{l}: {trained[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of the theoretical closure are : 1, 3/4, -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = np.array((trained[0], trained[1], trained[2])).flatten()\n",
    "trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical = np.array([1,3/4,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error = (trained - theoretical)/theoretical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de prévision réalisée avec le modèle calibré**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "closed_pkf_burgers.set_dt(dt)\n",
    "times = closed_pkf_burgers.window(1)\n",
    "saved_times = times[::50]\n",
    "print('saved_times :' ,saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_unclosed_traj = closed_pkf_burgers.forecast(times, state0, saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKF using trained closure\n",
    "plot_pkf_traj_NN(trained_unclosed_traj)\n",
    "plt.savefig('./figures/burgers-TrainableScalar-b.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble of forecast statistics\n",
    "plot_pkf_traj_ensemble(ensemble_traj)\n",
    "plt.savefig('./figures/burgers-TrainableScalar-a.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a id='conclusion'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have considered the uncertainty prediction for the Burgers dynamics where an unclosed term is present.\n",
    "\n",
    "A closure has been proposed and implemented as **a symbolic expression where unknown quantities are defined as `TrainableScalar`**\n",
    "which are translated into a trainable neural network.\n",
    "\n",
    "A synthetic dataset has been used to train the NN. The resulting closure has shown to be relevant to predict the uncertainty."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "nav_menu": {
    "height": "244px",
    "width": "212px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
